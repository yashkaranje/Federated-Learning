{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'C:\\Users\\Yash\\AppData\\Roaming\\Python\\Python36\\site-packages\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yash\\AppData\\Roaming\\Python\\Python36\\site-packages\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from data_processing import LoadData\n",
    "from model import *\n",
    "import syft as sy\n",
    "import copy\n",
    "hook = sy.TorchHook(torch)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    \n",
    "    dataset = pd.read_csv('PeMS_04/PeMS04.csv')\n",
    "    dataset_size = len(dataset)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split1 = int(np.floor(0.12 * dataset_size)) \n",
    "    split2 = int(np.floor(0.24 * dataset_size)) \n",
    "    split3 = int(np.floor(0.36 * dataset_size)) \n",
    "    split4 = int(np.floor(0.48 * dataset_size)) \n",
    "    split5 = int(np.floor(0.6 * dataset_size)) \n",
    "    split6 = int(np.floor(0.72 * dataset_size)) \n",
    "    split7 = int(np.floor(0.84 * dataset_size)) \n",
    "    bobs_indices, alices_indices, harrys_indices, jacks_indices, miks_indices, olivers_indices, kats_indices, elizas_indices = indices[:split1], indices[split1:split2], indices[split2:split3], indices[split3:split4], indices[split4:split5], indices[split5:split6], indices[split6:split7], indices[split7:]\n",
    "\n",
    "    bobs_sampler = SubsetRandomSampler(bobs_indices)\n",
    "    alices_sampler = SubsetRandomSampler(alices_indices)\n",
    "    harrys_sampler = SubsetRandomSampler(harrys_indices)\n",
    "    jacks_sampler = SubsetRandomSampler(jacks_indices)\n",
    "    miks_sampler = SubsetRandomSampler(miks_indices)\n",
    "    olivers_sampler = SubsetRandomSampler(olivers_indices)\n",
    "    kats_sampler = SubsetRandomSampler(kats_indices)\n",
    "    elizas_sampler = SubsetRandomSampler(elizas_indices)\n",
    "        \n",
    "    train_data = LoadData(data_path=[\"PeMS_04/PeMS04.csv\", \"PeMS_04/PeMS04.npz\"], num_nodes=307, divide_days=[45, 14],\n",
    "                              time_interval=5, history_length=6,\n",
    "                              train_mode=\"train\")\n",
    "\n",
    "\n",
    "    bobs_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=bobs_sampler)\n",
    "    alices_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=alices_sampler)\n",
    "    harrys_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=harrys_sampler)\n",
    "    jacks_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=jacks_sampler)\n",
    "    miks_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=miks_sampler)\n",
    "    olivers_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=olivers_sampler)\n",
    "    kats_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=kats_sampler)\n",
    "    elizas_loader = DataLoader(train_data, batch_size=64, num_workers=32, sampler=elizas_sampler)\n",
    "    \n",
    "#     bob alice harry jack    \n",
    "#     # Loading Dataset\n",
    "#     train_data = LoadData(data_path=[\"PeMS_04/PeMS04.csv\", \"PeMS_04/PeMS04.npz\"], num_nodes=307, divide_days=[45, 14],\n",
    "#                           time_interval=5, history_length=6,\n",
    "#                           train_mode=\"train\")\n",
    "\n",
    "#     train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=32)\n",
    "#....................................................\n",
    "#     test_data = LoadData(data_path=[\"PeMS_04/PeMS04.csv\", \"PeMS_04/PeMS04.npz\"], num_nodes=307, divide_days=[45, 14],\n",
    "#                          time_interval=5, history_length=6,\n",
    "#                          train_mode=\"test\")\n",
    "\n",
    "#     test_loader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=32)\n",
    "    \n",
    "#     for data in train_loader: \n",
    "#         print(data)\n",
    "\n",
    "    #model = GCN(in_c=6 , hid_c=6 ,out_c=1)\n",
    "    #ChebNet(in_c=6, hid_c=32, out_c=1, K=2)\n",
    "    #GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    bobs_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    bobs_model = bobs_model.to(device)\n",
    "    \n",
    "    alices_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    alices_model = alices_model.to(device)\n",
    "    \n",
    "    harrys_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    harrys_model = harrys_model.to(device)\n",
    "    \n",
    "    jacks_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    jacks_model = jacks_model.to(device)\n",
    "    \n",
    "    miks_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    miks_model = miks_model.to(device)\n",
    "    \n",
    "    olivers_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    olivers_model = olivers_model.to(device)\n",
    "    \n",
    "    kats_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    kats_model = kats_model.to(device)\n",
    "    \n",
    "    elizas_model = GATNet(in_c=6 , hid_c=6 ,out_c=1, n_heads=1)\n",
    "    elizas_model = elizas_model.to(device)\n",
    "    \n",
    "    #new\n",
    "    bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "    alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "    harry = sy.VirtualWorker(hook, id=\"harry\")\n",
    "    jack = sy.VirtualWorker(hook, id=\"jack\")\n",
    "    mik = sy.VirtualWorker(hook, id=\"mik\")\n",
    "    oliver = sy.VirtualWorker(hook, id=\"oliver\")\n",
    "    kat = sy.VirtualWorker(hook, id=\"kat\")\n",
    "    eliza = sy.VirtualWorker(hook, id=\"eliza\")\n",
    "    secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
    "\n",
    "    #new\n",
    "#     bobs_model = model.copy().send(bob)\n",
    "#     alices_model = model.copy().send(alice)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    #new\n",
    "    bobs_opt = optim.Adam(params=bobs_model.parameters())\n",
    "    alices_opt = optim.Adam(params=alices_model.parameters())\n",
    "    harrys_opt = optim.Adam(params=harrys_model.parameters())\n",
    "    jacks_opt = optim.Adam(params=jacks_model.parameters())\n",
    "    miks_opt = optim.Adam(params = miks_model.parameters())\n",
    "    olivers_opt = optim.Adam(params = olivers_model.parameters())\n",
    "    kats_opt = optim.Adam(params = kats_model.parameters())\n",
    "    elizas_opt = optim.Adam(params = elizas_model.parameters())\n",
    "    \n",
    "    \n",
    "    # Train model\n",
    "    Epoch = 8\n",
    "\n",
    "    bobs_model.train()\n",
    "    alices_model.train()\n",
    "    harrys_model.train()\n",
    "    jacks_model.train()\n",
    "    miks_model.train()\n",
    "    olivers_model.train()\n",
    "    kats_model.train()\n",
    "    elizas_model.train()\n",
    "    \n",
    "    for epoch in range(Epoch):\n",
    "    \t#new\n",
    "        epoch_loss_bob = 0.0\n",
    "        epoch_loss_alice = 0.0\n",
    "        epoch_loss_harry = 0.0\n",
    "        epoch_loss_jack = 0.0\n",
    "        epoch_loss_mik = 0.0\n",
    "        epoch_loss_oliver = 0.0\n",
    "        epoch_loss_kat = 0.0\n",
    "        epoch_loss_eliza = 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for data in bobs_loader:  # [\"graph\": [B, N, N] , \"flow_x\": [B, N, H, D], \"flow_y\": [B, N, 1, D]]\n",
    "            bobs_model.zero_grad()\n",
    "            predict_value = bobs_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_bob += loss.item()\n",
    "            loss.backward()\n",
    "            bobs_opt.step()\n",
    "            \n",
    "        for data in alices_loader:\n",
    "            alices_model.zero_grad()\n",
    "            predict_value = alices_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_alice += loss.item()\n",
    "            loss.backward()\n",
    "            alices_opt.step()\n",
    "            \n",
    "        for data in harrys_loader:\n",
    "            harrys_model.zero_grad()\n",
    "            predict_value = harrys_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_harry += loss.item()\n",
    "            loss.backward()\n",
    "            harrys_opt.step()\n",
    "            \n",
    "        for data in jacks_loader:\n",
    "            jacks_model.zero_grad()\n",
    "            predict_value = jacks_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_jack += loss.item()\n",
    "            loss.backward()\n",
    "            jacks_opt.step()    \n",
    "            \n",
    "        for data in miks_loader:\n",
    "            miks_model.zero_grad()\n",
    "            predict_value = miks_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_mik += loss.item()\n",
    "            loss.backward()\n",
    "            miks_opt.step()\n",
    "            \n",
    "        for data in olivers_loader:\n",
    "            olivers_model.zero_grad()\n",
    "            predict_value = olivers_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_oliver += loss.item()\n",
    "            loss.backward()\n",
    "            olivers_opt.step()  \n",
    "            \n",
    "        for data in kats_loader:\n",
    "            kats_model.zero_grad()\n",
    "            predict_value = kats_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_kat += loss.item()\n",
    "            loss.backward()\n",
    "            kats_opt.step()  \n",
    "         \n",
    "        for data in elizas_loader:\n",
    "            elizas_model.zero_grad()\n",
    "            predict_value = elizas_model(data, device).to(torch.device(\"cpu\"))  # [0, 1] -> recover\n",
    "            loss = criterion(predict_value, data[\"flow_y\"])\n",
    "            epoch_loss_eliza += loss.item()\n",
    "            loss.backward()\n",
    "            elizas_opt.step()  \n",
    "            \n",
    "        end_time = time.time()\n",
    "\n",
    "        print(\"Epoch: {:04d}, Loss Bob: {:02.4f}, Loss Alice: {:02.4f}, Loss Harry: {:02.4f}, Loss Jack: {:02.4f}, Loss Mik: {:02.4f}, Loss Oliver: {:02.4f}, Loss Kat: {:02.4f}, Loss Eliza: {:02.4f}, Time: {:02.2f} mins\".format(epoch, 1000 * epoch_loss_bob / len(train_data), 1000 * epoch_loss_alice / len(train_data), 1000 * epoch_loss_harry / len(train_data), 1000 * epoch_loss_jack / len(train_data), 1000 * epoch_loss_mik / len(train_data), 1000 * epoch_loss_oliver / len(train_data), 1000 * epoch_loss_kat / len(train_data), 1000 * epoch_loss_eliza / len(train_data),\n",
    "                                                                          (end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000, Loss Bob: 0.0092, Loss Alice: 0.0117, Loss Harry: 0.0125, Loss Jack: 0.2817, Loss Mik: 0.0089, Loss Oliver: 0.0114, Loss Kat: 1.4574, Loss Eliza: 0.0213, Time: 12.88 mins\n",
      "Epoch: 0001, Loss Bob: 0.0092, Loss Alice: 0.0117, Loss Harry: 0.0125, Loss Jack: 0.2781, Loss Mik: 0.0089, Loss Oliver: 0.0113, Loss Kat: 1.4467, Loss Eliza: 0.0208, Time: 12.98 mins\n",
      "Epoch: 0002, Loss Bob: 0.0092, Loss Alice: 0.0117, Loss Harry: 0.0125, Loss Jack: 0.2745, Loss Mik: 0.0089, Loss Oliver: 0.0113, Loss Kat: 1.4359, Loss Eliza: 0.0203, Time: 11.73 mins\n",
      "Epoch: 0003, Loss Bob: 0.0092, Loss Alice: 0.0117, Loss Harry: 0.0125, Loss Jack: 0.2710, Loss Mik: 0.0089, Loss Oliver: 0.0113, Loss Kat: 1.4253, Loss Eliza: 0.0198, Time: 11.00 mins\n",
      "Epoch: 0004, Loss Bob: 0.0092, Loss Alice: 0.0117, Loss Harry: 0.0125, Loss Jack: 0.2675, Loss Mik: 0.0089, Loss Oliver: 0.0112, Loss Kat: 1.4147, Loss Eliza: 0.0194, Time: 11.38 mins\n",
      "Epoch: 0005, Loss Bob: 0.0092, Loss Alice: 0.0117, Loss Harry: 0.0125, Loss Jack: 0.2640, Loss Mik: 0.0089, Loss Oliver: 0.0112, Loss Kat: 1.4041, Loss Eliza: 0.0189, Time: 11.47 mins\n",
      "Epoch: 0006, Loss Bob: 0.0092, Loss Alice: 0.0117, Loss Harry: 0.0125, Loss Jack: 0.2606, Loss Mik: 0.0089, Loss Oliver: 0.0111, Loss Kat: 1.3935, Loss Eliza: 0.0184, Time: 12.04 mins\n",
      "Epoch: 0007, Loss Bob: 0.0092, Loss Alice: 0.0116, Loss Harry: 0.0125, Loss Jack: 0.2571, Loss Mik: 0.0089, Loss Oliver: 0.0110, Loss Kat: 1.3831, Loss Eliza: 0.0180, Time: 13.13 mins\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
